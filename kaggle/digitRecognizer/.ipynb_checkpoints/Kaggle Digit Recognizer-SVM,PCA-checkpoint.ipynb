{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intoduction\n",
    "link to competition: [digit recogniger competition](https://www.kaggle.com/c/digit-recognizer)\n",
    "\n",
    "My Kaggle Profile: [Amit Vikram | Kaggle](https://www.kaggle.com/amitkvikram)\n",
    "\n",
    "- Here we will use PCA for dimensionality reduction and then train the data using \"Logistic Regression\" and \"BFGS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "Train = pd.read_csv(\"train.csv\").values\n",
    "Test = pd.read_csv(\"test.csv\").values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 784)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = Train[:,1:]\n",
    "Y = Train[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 612)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAJiCAYAAADpO+myAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nT4sG4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4339a01d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# ## Removing the column with variance 0\n",
    "variance = np.var(X, axis = 0)>10\n",
    "X = X[:, variance]\n",
    "Test = Test[:,variance]\n",
    "print(X.shape)\n",
    "# ##Calculate Principal Components\n",
    "pca = PCA()\n",
    "pca.fit(X)\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "# ##Calculate cumulative explained ration\n",
    "cum_explained_variance = [np.sum(explained_variance[:i+1]) for i in range (0, 201, 25)]\n",
    "X_axis = [i for i in range(0, 201,25)]\n",
    "\n",
    "##Plot Graph\n",
    "fig = plt.figure(figsize = (5.841, 7.195), dpi=100)\n",
    "plt.plot(X_axis, cum_explained_variance, 'ro')\n",
    "plt.grid(True, which = 'both')\n",
    "plt.yticks(cum_explained_variance)\n",
    "plt.xticks(X_axis)\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.xlabel(\"No. of Components\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So Looking on the above graph, 50 components comprise 80% variance. So first we will go with 50 componets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data for training and testing\n",
    "- Training data: 80%\n",
    "- Test data: 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size  = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def normalize(sigma2, mean2, X):\n",
    "    X = (X-mean2)/sigma2\n",
    "    return X\n",
    "\n",
    "def PolynomialFeatures1(X):\n",
    "    X_2 = np.square(X)\n",
    "    X = np.column_stack((X, X_2))\n",
    "    return X\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "\n",
    "# ### TRAINING\n",
    "# sigma = np.std(X_train, axis = 0)\n",
    "# mean = np.mean(X_train, axis = 0)\n",
    "\n",
    "# X_train = normalize(sigma , mean , X_train)\n",
    "# X_test = normalize(sigma , mean, X_test)\n",
    "\n",
    "##Take n principal components\n",
    "def PrincipalComponents(n):\n",
    "    pca = PCA(n_components= n)\n",
    "    X_train1 = pca.fit_transform(X_train)\n",
    "    X_test1 = pca.transform(X_test)\n",
    "    return X_train1, X_test1\n",
    "\n",
    "## logistic regression, Solver: 'lbfgs'\n",
    "\n",
    "def LogisticRegression(X_train2, y_train2, X_test2, y_test2, penalty):\n",
    "    print(\"penalty= \", penalty)\n",
    "    regr = linear_model.LogisticRegression(solver='lbfgs',max_iter=1000, C=penalty)\n",
    "    regr.fit(X_train2, y_train2)\n",
    "    score1 = regr.score(X_train2, y_train2)\n",
    "    score2 = regr.score(X_test2, y_test2)\n",
    "    print(score1, score2)\n",
    "    Prediction = regr.predict(X_test2)\n",
    "    return score1, score2, Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 50 Principal Componets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponents(50)\n",
    "X_test1 = add_X0(X_test1)\n",
    "X_train1 = add_X0(X_train1)\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(20000, X_train1.shape[0], 1000):\n",
    "    score1, score2, Prediction = LogisticRegression(X_train1[:i+1,:], y_train[:i+1, ], \n",
    "                                                    X_test1[:i+1,:], y_test[:i+1], 1.0)\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add polynomial features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 43) (33600, 43)\n",
      "(8400, 989) (33600, 989)\n",
      "penalty=  1\n",
      "1.0 0.974642857143\n",
      "penalty=  1\n",
      "1.0 0.975238095238\n",
      "penalty=  1\n",
      "1.0 0.975238095238\n",
      "penalty=  1\n",
      "0.999966102844 0.974642857143\n",
      "penalty=  1\n",
      "0.999967742976 0.975238095238\n",
      "penalty=  1\n",
      "0.999969231716 0.97630952381\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nECRJjYEgSQIMBElSYyBIkgD4f8qXaRLk3nvWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb4339a7b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "X_train1, X_test1 = PrincipalComponents(0.8)\n",
    "print(X_test1.shape, X_train1.shape)\n",
    "\n",
    "X_train1 = poly.fit_transform(X_train1)\n",
    "X_test1 = poly.transform(X_test1)\n",
    "\n",
    "print(X_test1.shape, X_train1.shape)\n",
    "\n",
    "sigma = np.std(X_train1, axis = 0)\n",
    "mean = np.mean(X_train1, axis = 0)\n",
    "\n",
    "X_train1 = normalize(sigma , mean , X_train1)\n",
    "X_test1 = normalize(sigma , mean, X_test1)\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(25000, X_train1.shape[0], 1500):\n",
    "    score1, score2, Prediction = LogisticRegression(X_train1[:i+1,:], \n",
    "                                                    y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1],1)\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8400, 43) (33600, 43)\n",
      "(8400, 989) (33600, 989)\n",
      "1.0 0.970238095238\n",
      "1.0 0.972023809524\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def supportVM(X_train2, y_train2, X_test2, y_test2, penalty):\n",
    "    regr = SVC(kernel ='linear', C=penalty)\n",
    "    regr.fit(X_train2, y_train2)\n",
    "    score1 = regr.score(X_train2, y_train2)\n",
    "    score2 = regr.score(X_test2, y_test2)\n",
    "    print(score1, score2)\n",
    "    Prediction = regr.predict(X_test2)\n",
    "    return score1, score2, Prediction\n",
    "\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "X_train1, X_test1 = PrincipalComponents(0.8)\n",
    "print(X_test1.shape, X_train1.shape)\n",
    "\n",
    "X_train1 = poly.fit_transform(X_train1)\n",
    "X_test1 = poly.transform(X_test1)\n",
    "\n",
    "print(X_test1.shape, X_train1.shape)\n",
    "\n",
    "sigma = np.std(X_train1, axis = 0)\n",
    "mean = np.mean(X_train1, axis = 0)\n",
    "\n",
    "X_train1 = normalize(sigma , mean , X_train1)\n",
    "X_test1 = normalize(sigma , mean, X_test1)\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(25000, X_train1.shape[0], 1500):\n",
    "    score1, score2, Prediction = supportVM(X_train1[:i+1,:], \n",
    "                                                    y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1],1)\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving data trained with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 43) (28000, 43)\n",
      "(42000, 989) (28000, 989)\n",
      "(42000, 989) (28000, 989)\n",
      "0.999833333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "\n",
    "X1 = X.copy()\n",
    "Test1 = Test.copy()\n",
    "\n",
    "pca = PCA(n_components= 0.8)\n",
    "X1 = pca.fit_transform(X1)\n",
    "Test1 = pca.transform(Test)\n",
    "\n",
    "print(X1.shape, Test1.shape)\n",
    "\n",
    "X1 = poly.fit_transform(X1)\n",
    "Test1 = poly.fit_transform(Test1)\n",
    "\n",
    "print(X1.shape, Test1.shape)\n",
    "\n",
    "sigma = np.std(X1, axis = 0)\n",
    "mean = np.mean(X1, axis = 0)\n",
    "\n",
    "X1 = normalize(sigma, mean, X1)\n",
    "Test1 = normalize(sigma , mean, Test1)\n",
    "print(X1.shape, Test1.shape)\n",
    "\n",
    "\n",
    "regr = linear_model.LogisticRegression(solver='lbfgs',max_iter=1000, C=1)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "pd.DataFrame({\"ImageId\": image_id, \"Label\": Prediction}).to_csv('out.csv', \n",
    "                                                                      index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Saving prediction trained with SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(include_bias = False)\n",
    "\n",
    "X1 = X.copy()\n",
    "Test1 = Test.copy()\n",
    "\n",
    "pca = PCA(n_components= 0.8)\n",
    "X1 = pca.fit_transform(X1)\n",
    "Test1 = pca.transform(Test)\n",
    "\n",
    "print(X1.shape, Test1.shape)\n",
    "\n",
    "X1 = poly.fit_transform(X1)\n",
    "Test1 = poly.fit_transform(Test1)\n",
    "\n",
    "print(X1.shape, Test1.shape)\n",
    "\n",
    "sigma = np.std(X1, axis = 0)\n",
    "mean = np.mean(X1, axis = 0)\n",
    "\n",
    "X1 = normalize(sigma, mean, X1)\n",
    "Test1 = normalize(sigma , mean, Test1)\n",
    "print(X1.shape, Test1.shape)\n",
    "\n",
    "\n",
    "regr = SVC(kernel ='linear', C=penalty)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "pd.DataFrame({\"ImageId\": image_id, \"Label\": Prediction}).to_csv('out_svm.csv', \n",
    "                                                                      index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X1 = X.copy()\n",
    "X1 = min_max_scaler.fit_transform(X1)\n",
    "Test1 = Test.copy()\n",
    "Test1= min_max_scaler.transform(Test1)\n",
    "\n",
    "pca = PCA(n_components = 50)\n",
    "pca.fit(X1)\n",
    "X1 = pca.fit_transform(X1)\n",
    "Test1 = pca.transform(Test1)\n",
    "\n",
    "X1_2 = np.square(X1)\n",
    "X1 = np.column_stack((X1, X1_2))\n",
    "Test1_2 = np.square(Test1)\n",
    "Test1 = np.column_stack((Test1, Test1_2))\n",
    "\n",
    "X1 = add_X0(X1)\n",
    "Test1 = add_X0(Test1)\n",
    "print(X1.shape)\n",
    "\n",
    "regr = linear_model.LogisticRegression(solver = 'lbfgs',max_iter=1000)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "Prediction = np.column_stack((image_id, Prediction))\n",
    "np.savetxt(\"prediction1.csv\", Prediction, header='ImageId,Label', delimiter=',', \n",
    "           fmt='%i',newline='\\n', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 100 Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponents(100)\n",
    "X_test1 = add_X0(X_test1)\n",
    "X_train1 = add_X0(X_train1)\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(1000, X_train1.shape[0], 1500):\n",
    "    score1, score2, Prediction = LogisticRegression(X_train1[:i+1,:], y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1])\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')  #training error\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X1 = X.copy()\n",
    "X1 = min_max_scaler.fit_transform(X1)\n",
    "Test1 = Test.copy()\n",
    "Test1= min_max_scaler.transform(Test1)\n",
    "\n",
    "pca = PCA(n_components = 100)\n",
    "pca.fit(X1)\n",
    "X1 = pca.fit_transform(X1)\n",
    "Test1 = pca.transform(Test1)\n",
    "\n",
    "X1_2 = np.square(X1)\n",
    "X1 = np.column_stack((X1, X1_2))\n",
    "Test1_2 = np.square(Test1)\n",
    "Test1 = np.column_stack((Test1, Test1_2))\n",
    "\n",
    "X1 = add_X0(X1)\n",
    "Test1 = add_X0(Test1)\n",
    "print(X1.shape)\n",
    "\n",
    "regr = linear_model.LogisticRegression(solver = 'lbfgs',max_iter=1000)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "Prediction = np.column_stack((image_id, Prediction))\n",
    "np.savetxt(\"prediction2.csv\", Prediction, header='ImageId,Label', delimiter=',', \n",
    "           fmt='%i',newline='\\n', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 150 Principal Componets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponents(150)\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(20000, X_train1.shape[0], 1000):\n",
    "    score1, score2, Prediction = LogisticRegression(X_train1[:i+1,:], y_train[:i+1, ],\n",
    "                                                    X_test1[:i+1,:], y_test[:i+1],1.0)\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')  #training error\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponents(150)\n",
    "\n",
    "X_train1 = PolynomialFeatures1(X_train1)\n",
    "X_test1 = PolynomialFeatures1(X_test1)\n",
    "\n",
    "### TRAINING\n",
    "sigma = np.std(X_train1, axis = 0)\n",
    "mean = np.mean(X_train1, axis = 0)\n",
    "\n",
    "X_train1 = normalize(sigma , mean , X_train1)\n",
    "X_test1 = normalize(sigma , mean, X_test1)\n",
    "\n",
    "print(X_test1.shape)\n",
    "print(X_train1.shape)\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "for penalty in [1.0]:\n",
    "    for i in range(30000, X_train1.shape[0], 1500):\n",
    "        score1, score2, Prediction = LogisticRegression(X_train1[:i+1,:], \n",
    "                                                        y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1],penalty)\n",
    "        J1.append(1-score1)\n",
    "        J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "    plt.plot(J2, 'b-')\n",
    "    plt.plot(J1, 'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponents(150)\n",
    "\n",
    "X_train1 = PolynomialFeatures1(X_train1)\n",
    "X_test1 = PolynomialFeatures1(X_test1)\n",
    "\n",
    "### TRAINING\n",
    "sigma = np.std(X_train1, axis = 0)\n",
    "mean = np.mean(X_train1, axis = 0)\n",
    "\n",
    "X_train1 = normalize(sigma , mean , X_train1)\n",
    "X_test1 = normalize(sigma , mean, X_test1)\n",
    "\n",
    "print(X_test1.shape)\n",
    "print(X_train1.shape)\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "for penalty in [1.0]:\n",
    "    for i in range(30000, X_train1.shape[0], 1500):\n",
    "        score1, score2, Prediction = LogisticRegression(X_train1[:i+1,:], \n",
    "                                                        y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1],penalty)\n",
    "        J1.append(1-score1)\n",
    "        J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "    plt.plot(J2, 'b-')\n",
    "    plt.plot(J1, 'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "min_max_scaler = MinMaxScaler()\n",
    "X1 = X.copy()\n",
    "# X1 = min_max_scaler.fit_transform(X1)\n",
    "Test1 = Test.copy()\n",
    "# Test1= min_max_scaler.transform(Test1)\n",
    "X1 = X1/\n",
    "\n",
    "pca = PCA(n_components = 150)\n",
    "pca.fit(X1)\n",
    "X1 = pca.fit_transform(X1)\n",
    "Test1 = pca.transform(Test1)\n",
    "\n",
    "X1_2 = np.square(X1)\n",
    "X1 = np.column_stack((X1, X1_2))\n",
    "Test1_2 = np.square(Test1)\n",
    "Test1 = np.column_stack((Test1, Test1_2))\n",
    "\n",
    "X1 = add_X0(X1)\n",
    "Test1 = add_X0(Test1)\n",
    "print(X1.shape)\n",
    "\n",
    "regr = linear_model.LogisticRegression(solver = 'lbfgs',max_iter=10000)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "Prediction = np.column_stack((image_id, Prediction))\n",
    "np.savetxt(\"prediction1.csv\", Prediction, header='ImageId,Label', delimiter=',', \n",
    "           fmt='%i',newline='\\n', comments='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_trainN, X_testN, y_trainN, y_testN = train_test_split(X, Y, test_size  = 0.20, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_trainN = np.multiply(X_trainN, 1.0/255.0)\n",
    "X_testN = np.multiply(X_testN, 1.0/255.0)\n",
    "##Take n principal components\n",
    "def PrincipalComponentsN(n):\n",
    "    pca = PCA(n_components= n)\n",
    "    X_train1 = pca.fit_transform(X_trainN)\n",
    "    X_test1 = pca.transform(X_testN)\n",
    "    return X_train1, X_test1\n",
    "def supportVM(X_train2, y_train2, X_test2, y_test2):\n",
    "    regr = SVC(C=2)\n",
    "    regr.fit(X_train2, y_train2)\n",
    "    score1 = regr.score(X_train2, y_train2)\n",
    "    score2 = regr.score(X_test2, y_test2)\n",
    "    print(score1, score2)\n",
    "    Prediction = regr.predict(X_test2)\n",
    "    return score1, score2, Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponentsN(150)\n",
    "\n",
    "# X_train1 = PolynomialFeatures(X_train1)\n",
    "# X_test1 = PolynomialFeatures(X_test1)\n",
    "\n",
    "X_test1 = add_X0(X_test1)\n",
    "X_train1 = add_X0(X_train1)\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(30000, X_train1.shape[0], 1500):\n",
    "    score1, score2, Prediction = supportVM(X_train1[:i+1,:], \n",
    "                                                    y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1])\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1 = PrincipalComponentsN(0.99)\n",
    "\n",
    "# X_train1 = PolynomialFeatures(X_train1)\n",
    "# X_test1 = PolynomialFeatures(X_test1)\n",
    "\n",
    "X_test1 = add_X0(X_test1)\n",
    "X_train1 = add_X0(X_train1)\n",
    "\n",
    "J1 = []\n",
    "J2 = []\n",
    "for i in range(33500, X_train1.shape[0], 1500):\n",
    "    score1, score2, Prediction = supportVM(X_train1[:i+1,:], \n",
    "                                                    y_train[:i+1, ], X_test1[:i+1,:], y_test[:i+1])\n",
    "    J1.append(1-score1)\n",
    "    J2.append(1-score2)\n",
    "    \n",
    "    \n",
    "plt.plot(J2, 'b-')\n",
    "plt.plot(J1, 'r-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "def add_X0(X):\n",
    "    np.column_stack((np.ones(X.shape[0],), X))\n",
    "    return X\n",
    "# min_max_scaler = MinMaxScaler()\n",
    "X1 = X.copy()\n",
    "print(X1.shape)\n",
    "# X1 = min_max_scaler.fit_transform(X1)\n",
    "Test1 = Test.copy()\n",
    "# Test1= min_max_scaler.transform(Test1)\n",
    "\n",
    "pca = PCA(n_components = 0.99, whiten = True)\n",
    "pca.fit(X1)\n",
    "X1 = pca.fit_transform(X1)\n",
    "print(X1.shape)\n",
    "Test1 = pca.transform(Test1)\n",
    "print(X1)\n",
    "\n",
    "# X1_2 = np.square(X1)\n",
    "# X1 = np.column_stack((X1, X1_2))\n",
    "# Test1_2 = np.square(Test1)\n",
    "# Test1 = np.column_stack((Test1, Test1_2))\n",
    "\n",
    "X1 = add_X0(X1)\n",
    "Test1 = add_X0(Test1)\n",
    "print(X1.shape)\n",
    "\n",
    "regr =  SVC(kernel = 'rbf', C=2)\n",
    "regr.fit(X1, Y)\n",
    "score1 = regr.score(X1, Y)\n",
    "print(score1)\n",
    "Prediction = regr.predict(Test1)\n",
    "image_id = np.arange(1,Prediction.shape[0]+1)\n",
    "print(\"here\")\n",
    "# Prediction = np.column_stack((image_id, Prediction))\n",
    "# np.savetxt(\"prediction1.csv\", Prediction, header='ImageId,Label', delimiter=',', \n",
    "#            fmt='%i',newline='\\n', comments='')\n",
    "pd.DataFrame({\"ImageId\": image_id, \"Label\": Prediction}).to_csv('out.csv', \n",
    "                                                                          index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
