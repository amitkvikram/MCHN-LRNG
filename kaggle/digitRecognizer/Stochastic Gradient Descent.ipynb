{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Digit Recognizer using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "raw_data = open(\"train.csv\",'rt')\n",
    "data = np.loadtxt(raw_data, delimiter = ',', skiprows =1)\n",
    "\n",
    "data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "    - training data : 60%\n",
    "    - test data: 20%\n",
    "    - cross validation data: 20%\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.873928571429 0.883333333333\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEACAYAAACpoOGTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\najIgJElNBoQkqcmAkCQ1GRCSpKb/Dy/AxBrXbX8RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa580ac5048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "\n",
    "pca = PCA(n_components=25)\n",
    "\n",
    "def normalize(sigma2, mean2, X):\n",
    "    X = (X-mean2)/sigma2\n",
    "    return X\n",
    "\n",
    "def add_x0(X):\n",
    "    return np.column_stack((np.zeros(X.shape[0],), X))\n",
    "\n",
    "J1=[];\n",
    "J2=[];\n",
    "# variance = (np.var(data[:,1:], axis =0)>1000)\n",
    "# X_train = X_train1[:,variance]\n",
    "raw_data = open(\"test.csv\",'rt')\n",
    "test_X = np.loadtxt(raw_data, delimiter = ',', skiprows =1)\n",
    "# sigma = np.std(X_train, axis =0)\n",
    "# mean = np.mean(X_train, axis =0)\n",
    "# sigma1 = np.std(X_train1, axis =0)\n",
    "# mean1 = np.mean(X_train1, axis =0)\n",
    "X_test1 = data[33600:, 1:]\n",
    "\n",
    "# y_cv = data[25200:33600, 0]\n",
    "\n",
    "y_test = data[33600:, 0]\n",
    "for i in range(34000,34001,1000):\n",
    "    y_train = data[:, 0]\n",
    "    X_train1 = data[:,1:]\n",
    "    pca.fit(X_train1)\n",
    "    X_train2 = pca.transform(X_train1)\n",
    "#     poly = PolynomialFeatures(2, include_bias=False)\n",
    "#     X_train2 = poly.fit_transform(X_train2)\n",
    "    # X_train1 = normalize(sigma1, mean1 , X_train1)      #without removing columns with less variance\n",
    "    # X_train = normalize(sigma , mean , X_train)\n",
    "\n",
    "    # print(X_train.shape)\n",
    "    # print(np.var(X_train, axis =0))\n",
    "\n",
    "    # X_cv1 = data[25200:33600, 1:]\n",
    "    # X_cv = X_cv1[:,variance]\n",
    "    # X_cv2 = X_cv\n",
    "    # X_cv = normalize(sigma , mean , X_cv)\n",
    "    # X_cv1 = normalize(sigma1 , mean1 , X_cv1)\n",
    "\n",
    "    # X_test = X_test1[:,variance]\n",
    "    # X_test = normalize(sigma , mean , X_test)\n",
    "    # X_test1 = normalize(sigma1 , mean1 , X_test1)\n",
    "    X_test2 = pca.transform(X_test1)\n",
    "#     X_test2  = poly.fit_transform(X_test2)\n",
    "    test_X = pca.transform(test_X)\n",
    "#     test_X = poly.fit_transform(test_X)\n",
    "    #Adding x0\n",
    "    # X_train1= add_x0(X_train1)\n",
    "    # X_cv1= add_x0(X_cv1)\n",
    "    # X_cv= add_x0(X_cv)\n",
    "    # X_test1 = add_x0(X_test1)\n",
    "    ###########################\n",
    "    regr = linear_model.LogisticRegression(solver='lbfgs')\n",
    "\n",
    "    regr.fit(X_train2, y_train)\n",
    "    score1 = regr.score(X_train2, y_train)\n",
    "    score2 = regr.score(X_test2, y_test)\n",
    "    theta = np.column_stack((regr.intercept_, regr.coef_))\n",
    "\n",
    "    np.savetxt(\"del.txt\", theta.T, delimiter =',', newline='\\n')\n",
    "    test_Y = regr.predict(test_X)\n",
    "    image_id = np.arange(1,test_Y.shape[0]+1)\n",
    "    test_Y = np.column_stack((image_id, test_Y))\n",
    "    np.savetxt('prediction.csv', test_Y, header='ImageId,Label', delimiter=',', fmt='%i',newline='\\n', comments='')\n",
    "    print(score1, score2)\n",
    "    J1.append(1 - score1)\n",
    "    J2.append(1 - score2)\n",
    "\n",
    "plt.plot(J1,'b-')\n",
    "plt.plot(J2,'r-')\n",
    "plt.show()\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "# print(X_train.shape, X_cv.shape, X_test.shape)\n",
    "# print(y_train.shape, y_cv.shape, y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "#Adding polynomial features\n",
    "# poly = PolynomialFeatures(1, include_bias=False)\n",
    "# X_train = poly.fit_transform(X_train)\n",
    "# X_test = poly.fit_transform(X_test)\n",
    "# X_train= add_x0(X_train)\n",
    "# X_test = add_x0(X_test)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw_data2 = open(\"prediction.csv\",'rt')\n",
    "prediction = np.loadtxt(raw_data2, delimiter = ',', skiprows =1)\n",
    "image_id = np.arange(1,prediction.shape[0]+1)\n",
    "prediction = np.column_stack((image_id, prediction))\n",
    "\n",
    "np.savetxt('prediction.csv', prediction, header='ImageId,Label', delimiter=',', fmt='%i',newline='\\n', comments='')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "theta = np.zeros((X_train.shape[1],10)) \n",
    "def cost(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    J = (1/(2*m))*np.sum(np.square(np.dot(X,theta) -y))\n",
    "\n",
    "    return J;\n",
    "\n",
    "def hypothesis(x_tmp, theta1):\n",
    "    h = np.dot(np.transpose(x_tmp), theta1)\n",
    "    h_temp = h[0,0]\n",
    "    h_temp = 1/(1+np.exp(-h_temp))\n",
    "#     print(h_temp)\n",
    "    return h_temp\n",
    "\n",
    "def stochastic_gradientDescent(X, y, theta):\n",
    "    m = X.shape[0]\n",
    "    alpha = 0.0001\n",
    "    for k in range(0,10):\n",
    "        print(k)\n",
    "        for i in range(1,10):\n",
    "            for j in range(1,m):\n",
    "                x_tmp = X[i, :]\n",
    "                x_tmp = x_tmp.reshape(x_tmp.shape[0], 1)\n",
    "                y_tmp = (y[i] == k).astype(np.float64)\n",
    "                theta1 = theta[:,k].reshape(theta[:,k].shape[0],1)\n",
    "                theta[:,k] = (theta1 -(np.dot((alpha*x_tmp),(hypothesis(x_tmp, theta1) - y_tmp)))).reshape(theta1.shape[0], ) \n",
    "#                 print(\"theta=\",theta[:,k])\n",
    "#             print(cost(x_tmp, y_tmp, theta[:,k]))\n",
    "\n",
    "stochastic_gradientDescent(X_train, y_train, theta) \n",
    "print(theta)\n",
    "np.savetxt(\"del.txt\", theta, delimiter =',', newline='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import  numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.SGDClassifier(alpha = 0.0001)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "theta = np.zeros((X_train2.shape[1]+1,10)) \n",
    "\n",
    "print(clf.score(X_test, y_test))\n",
    "\n",
    "theta = np.column_stack((clf.intercept_, clf.coef_))\n",
    "# print(theta.T)\n",
    "print(clf.get_params(deep = True))\n",
    "\n",
    "np.savetxt(\"del.txt\", theta.T, delimiter =',', newline='\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BFGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892291666667 0.888095238095\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "regr = linear_model.LogisticRegression(solver='lbfgs')\n",
    "\n",
    "regr.fit(X_train2, y_train)\n",
    "score1 = regr.score(X_train2, y_train)\n",
    "score = regr.score(X_test2, y_test)\n",
    "print(score1, score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
